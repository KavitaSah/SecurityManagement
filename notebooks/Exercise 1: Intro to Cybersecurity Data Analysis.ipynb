{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Introduction to Cybersecurity Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Please complete the notebook below, answering **[Questions]** and completing **[Tasks]**.  You're welcome to work with a partner, but everyone is individually responsibile for submitting their assignment.  (turning in both the .ipynb notebook and PDF document).    \n",
    "\n",
    "Due: next **Wednesday, January 23 @ 6PM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports, jupyter magic commands\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file\n",
    "conn_log_data_path = 'data/conn.log'\n",
    "# for colab, use:\n",
    "# conn_log_data_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "First off, let's take a look at a log file generated from Bro this log is similar to netflow logs as well. However, this log file is rather large and doesn't fit in memory.  \n",
    "As part of the first exercise, figure out what setting the variable sample_percent should be in order to read in between 200k and 300k worth of (randomly selected) lines from the file. Change the variable, after doing that either click the play button above (it's the arrow) or hit the [Shift]+[Enter] keys as the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22694356 lines in data/conn.log, using a sample of 9077742 lines\n"
     ]
    }
   ],
   "source": [
    "logfile = conn_log_data_path\n",
    "sample_percent = .4\n",
    "num_lines = sum(1 for line in open(logfile))\n",
    "slines = set(sorted(random.sample(range(num_lines), int(num_lines * sample_percent))))\n",
    "print(\"{} lines in {}, using a sample of {} lines\".format(num_lines, logfile, len(slines)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Creation**  \n",
    "Let's write that sample to a logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile = 'data/conn_sample.log'\n",
    "f = open(outfile, 'w+')\n",
    "i = open(logfile, 'r+')\n",
    "\n",
    "linecount = 0\n",
    "for line in i:\n",
    "    if linecount in slines:\n",
    "        f.write(line)\n",
    "    linecount += 1\n",
    "f.close()\n",
    "i.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading CSVs with Pandas**\n",
    "This next cell does a couple of things, first it imports pandas so we can create a dataframe, and then it reads our newly created file from above into memory. You can see the separator is specified to \"\\t\" because Bro produces tab-delimited files by default. In this case we've also specified what we should call the columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(outfile, sep=\"\\t\", header=None, nrows=100000, \n",
    "                 names=['ts','uid','id.orig_h','id.orig_p','id.resp_h','id.resp_p','proto','service','duration','orig_bytes','resp_bytes','conn_state','local_orig','missed_bytes','history','orig_pkts','orig_ip_bytes','resp_pkts','resp_ip_bytes','tunnel_parents','threat','sample'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(conn_log_data_path, sep=\"\\t\", header=None, nrows=100000, \n",
    "                 names=['ts','uid','id.orig_h','id.orig_p','id.resp_h','id.resp_p','proto','service','duration','orig_bytes','resp_bytes','conn_state','local_orig','missed_bytes','history','orig_pkts','orig_ip_bytes','resp_pkts','resp_ip_bytes','tunnel_parents','threat','sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pd.read_csv reads in a CSV\n",
    "- nrows: the number of lines to read in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task]** View DataFrame  \n",
    "use .head() to show first 10 rows of DataFrame ('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Questions & Tasks\n",
    "**[Question]** What is Bro Network Monitor?  \n",
    "**[Question]** What is it used for?  \n",
    "**[Question]** What are the different log file types and what do they describe?  What is the log file type that we have for this exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore Data\n",
    "## Pandas Data Manipulation\n",
    "**[Task]** use .shape on df to show the rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Summarization**  \n",
    "You can see a summary of all of the numerical columns with .describe()  \n",
    "**[Task]** use .describe() on df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why doesn't the ts column look like a timestamp?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Types**  \n",
    "**[Task]** use .dtypes on df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** What kind of datatype is df['ts']?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Column Data Types**  \n",
    "Time to change the ts column to a datetime object! We will accomplish that by using a simple function provided called to_datetime(). The cell below runs this function on the ts column (what should be a time stamp), and then re-assigns this column back to the dataframe in the same place. A new timestamp column could have been added to the dataframe as well so both the float value and the datetime object columns are present.  \n",
    "\n",
    "Run the cell below to convert the column type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ts'] = [datetime.fromtimestamp(float(date)) for date in df['ts'].values]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task]** It's really handy to set the index to the timestamp.  Use .set_index() to set the dataframe index to 'ts' columns.  Use the argument, inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task/Question]** Verify that the conversion was successful. What is the datatype of the column now?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scroll back up the page and note where you ran the describe() function. You'll see under the threat and sample columns there is likely the value of NaN. This stands for Not a Number and is a special value assigned to empty column values. There are a few ways to explore what values a column has. Two of these are value_counts() and unique().  \n",
    "\n",
    "**[Task]** Try .value_counts() and .unique() below on different columns in the DataFrame. You can create new cells or if you want to get more than the last command worth of output you can put a print statement in front.  \n",
    "\n",
    "**[Question]** What happens when you run them on a column with IPs (id.orig_h, id.resp_h)? What about sample or threat?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Unnecessary Columns**  \n",
    "Let's drop the threat and sample columns since they are empty.   \n",
    "**[Task]** Search pandas documentation for using the .drop() method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row Selection**  \n",
    "Let's find all the rows  where the value in a column match a keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl = df[df['service'] == 'ssl']\n",
    "ssl.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** What type of data is in the SSL DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take that subset of the dataframe, the SSL service rows, and then do further filtering..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_df = df[df['service'] == 'ssl']\n",
    "ssl_df[ssl_df['id.resp_p'] != 443].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_df = df[df['service'] == 'http']\n",
    "http_df[http_df['id.resp_p'] != 80]['id.orig_h'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Tasks & Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** What is the line [ssl_df[ssl_df['id.resp_p'] != 443].head()] doing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task]** Show rows that use a service on a non-standard port  \n",
    "Hint: first identify all of the protocols in the service columns   \n",
    "**[Question]** What can this type of filtering be used for?  (Why do we care to know that services are being used on a non-standard port?  Can you identify an attack that uses this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** What five IP adddresses have the most traffic coming from them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SSH Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ssh.log', sep=\"\\t\", header=None, usecols=[0,1,2,3,4,5,6,7,8,9],names=['ts', 'uid', 'src_ip', 'src_port', 'server', 'server_port', 'auth_success', 'direction', 'version', 'version2'])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** How many records are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task]** Convert Time  \n",
    "**[Question]** What's the begin date and end dates of the dataset?  hint: .max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Question]** What proportion of the records were successful at authenticating? hint: normalize=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Task]** Did any of the records use a non-standard SSH port?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
